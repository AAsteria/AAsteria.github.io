{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-22T23:24:12.443549Z","iopub.execute_input":"2022-01-22T23:24:12.443930Z","iopub.status.idle":"2022-01-22T23:24:12.454507Z","shell.execute_reply.started":"2022-01-22T23:24:12.443896Z","shell.execute_reply":"2022-01-22T23:24:12.453787Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np # 科学计算工具\nimport pandas as pd # 数据处理工具\nimport matplotlib.pyplot as plt # 数据可视化基础工具\nimport seaborn as sns #高阶数据可视化\nfrom scipy.stats import skew, norm # 计算skew和norm的函数\nimport math # 数学处理函数\nplt.style.use('ggplot')  # 设置绘图风格\nfrom sklearn.preprocessing import MinMaxScaler # 数据归一化工具\nfrom sklearn.ensemble import GradientBoostingRegressor ## GBDT\nfrom lightgbm import LGBMRegressor # LGBM\nfrom xgboost import XGBRegressor # xgboost\nfrom sklearn.metrics import mean_squared_error, make_scorer  ## 计算均方差函数\nfrom time import time\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:16.946964Z","iopub.execute_input":"2022-01-22T23:24:16.947479Z","iopub.status.idle":"2022-01-22T23:24:19.685931Z","shell.execute_reply.started":"2022-01-22T23:24:16.947439Z","shell.execute_reply":"2022-01-22T23:24:19.684995Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"#导入训练集数据 （本地使用）\ntrain = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv') # 其中的参数为路径\n#导入测试集数据\ntest = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')   # 其中的参数为路径\nSalePrice = np.log(train['SalePrice'])  # 对房价做对数化处理\ndata= pd.concat([train,test], keys=['train', 'test'])# X 是 training data Y 是 testing data\ndata=data.drop([\"Id\"],axis=1) # 因为原始数据中的数据索引和预测模型的构建没有关系，直接删掉\n\n## 删去缺失值超过15%的特征\nx =  data.isnull().sum().sort_values(ascending=False)/len(data)\nmissing_ratio = data.isnull().sum().sort_values(ascending=False)/len(data)\nmissing_ratio_2 = missing_ratio.copy()\nmissing_ratio_2.drop(missing_ratio_2[missing_ratio_2 == 0].index, inplace =True)\ndata = data.drop(missing_ratio[missing_ratio > 0.15].index,1) ","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:24.102480Z","iopub.execute_input":"2022-01-22T23:24:24.102738Z","iopub.status.idle":"2022-01-22T23:24:24.173659Z","shell.execute_reply.started":"2022-01-22T23:24:24.102712Z","shell.execute_reply":"2022-01-22T23:24:24.172947Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:25.783092Z","iopub.execute_input":"2022-01-22T23:24:25.783439Z","iopub.status.idle":"2022-01-22T23:24:25.788993Z","shell.execute_reply.started":"2022-01-22T23:24:25.783414Z","shell.execute_reply":"2022-01-22T23:24:25.788268Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(2919, 73)"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:27.984035Z","iopub.execute_input":"2022-01-22T23:24:27.984443Z","iopub.status.idle":"2022-01-22T23:24:28.017344Z","shell.execute_reply.started":"2022-01-22T23:24:27.984412Z","shell.execute_reply":"2022-01-22T23:24:28.015903Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\ntrain 0          60       RL     8450   Pave      Reg         Lvl    AllPub   \n      1          20       RL     9600   Pave      Reg         Lvl    AllPub   \n      2          60       RL    11250   Pave      IR1         Lvl    AllPub   \n      3          70       RL     9550   Pave      IR1         Lvl    AllPub   \n      4          60       RL    14260   Pave      IR1         Lvl    AllPub   \n\n        LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch  \\\ntrain 0    Inside       Gtl      CollgCr  ...          61             0   \n      1       FR2       Gtl      Veenker  ...           0             0   \n      2    Inside       Gtl      CollgCr  ...          42             0   \n      3    Corner       Gtl      Crawfor  ...          35           272   \n      4       FR2       Gtl      NoRidge  ...          84             0   \n\n        3SsnPorch ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType  \\\ntrain 0         0           0         0        0       2    2008       WD   \n      1         0           0         0        0       5    2007       WD   \n      2         0           0         0        0       9    2008       WD   \n      3         0           0         0        0       2    2006       WD   \n      4         0           0         0        0      12    2008       WD   \n\n        SaleCondition  \ntrain 0        Normal  \n      1        Normal  \n      2        Normal  \n      3       Abnorml  \n      4        Normal  \n\n[5 rows x 73 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>LandSlope</th>\n      <th>Neighborhood</th>\n      <th>...</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">train</th>\n      <th>0</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>CollgCr</td>\n      <td>...</td>\n      <td>61</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>Gtl</td>\n      <td>Veenker</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>CollgCr</td>\n      <td>...</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>RL</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>Gtl</td>\n      <td>Crawfor</td>\n      <td>...</td>\n      <td>35</td>\n      <td>272</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>Gtl</td>\n      <td>NoRidge</td>\n      <td>...</td>\n      <td>84</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 73 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#对于列名为'MSSubClass'、'YrSold'、'MoSold'的特征列，将列中的数据类型转化为string格式。\ndata['MSSubClass'] = data['MSSubClass'].apply(str)\ndata['YrSold'] = data['YrSold'].astype(str)\ndata['MoSold'] = data['MoSold'].astype(str)\n#按照以下各个特征列的实际情况，依次处理各个特征列中的空值（.fillna()方法）\ndata['Functional'] = data['Functional'].fillna('Typ') #空值填充为str型数据'Typ'\ndata['Electrical'] = data['Electrical'].fillna(\"SBrkr\") #空值填充为str型数据\"SBrkr\"\ndata['KitchenQual'] = data['KitchenQual'].fillna(\"TA\") #空值填充为str型数据\"TA\"\n\n\n#对于列名为'Exterior1st'、'Exterior2nd'、'SaleType'的特征列，使用列中的众数填充空值。\n# 1.先查找数据列中的众数：使用df.mode()[]方法\n#v解释：df.mode(0或1,0表示对列查找，1表示对行查找)[需要查找众数的df列的index（就是df中的第几列）]，将返回数据列中的众数\n# 2.使用.fillna()方法进行填充\ndata['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0]) \ndata['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\ndata['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])\n\n\n#对于列名为'GarageYrBlt', 'GarageArea', 'GarageCars'的特征列，使用0填充空值。\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    data[col] = data[col].fillna(0)\n\n#对于列名为'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'的特征列，使用字符串'None'填充空值。\nfor col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n    data[col] = data[col].fillna('None')\n    \n    \n#对于列名为'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'的特征列，使用字符串'None'填充空值。\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    data[col] = data[col].fillna('None')","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:30.177223Z","iopub.execute_input":"2022-01-22T23:24:30.177494Z","iopub.status.idle":"2022-01-22T23:24:30.209425Z","shell.execute_reply.started":"2022-01-22T23:24:30.177470Z","shell.execute_reply":"2022-01-22T23:24:30.207952Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#聚合函数（按某一列关键字分组）groupby，它的特点是：将返回与传入方法的矩阵维度相同的单个序列。\n#transform是与groupby（pandas中最有用的操作之一）通常组合使用，它对传入方法的矩阵进行维度不变的变换。具体变换方法写在括号中，通常会使用匿名函数，对传入矩阵的所有元素进行操作。\n#对于features矩阵，按照'MSSubClass'列中的元素分布进行分组，被分组的数据列是'MSZoning'列。data.groupby(被作为索引的列的名称)[被分组的数据列的名称]\n#data.groupby('MSSubClass')['MSZoning']后，得到的是一个以'MSSubClass'为索引，以'MSZoning'为数据列的矩阵。\n#.transform()方法将对'MSZoning'数据列进行()内的变换，它将返回和传入矩阵同样维度的矩阵。\n#括号内是匿名函数，将对传入矩阵中的空值进行填充，使用的填充元素是传入矩阵中的众数。\ndata['MSZoning'] = data.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:33.501780Z","iopub.execute_input":"2022-01-22T23:24:33.502541Z","iopub.status.idle":"2022-01-22T23:24:33.529234Z","shell.execute_reply.started":"2022-01-22T23:24:33.502503Z","shell.execute_reply":"2022-01-22T23:24:33.527809Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#判断出features矩阵中列为对象的列，将列名存入objects叔祖。对于data矩阵中的各个列对象，将其列中的空值填充为'None'\nobjects = []\nfor i in data.columns:\n    if data[i].dtype == object:\n        objects.append(i)\ndata.update(data[objects].fillna('None'))\n\n#对于整型和浮点型数据列，使用0填充其中的空值。\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics = []\nfor i in data.columns:\n    if data[i].dtype in numeric_dtypes:\n        numerics.append(i)\ndata.update(data[numerics].fillna(0))","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:35.217724Z","iopub.execute_input":"2022-01-22T23:24:35.218508Z","iopub.status.idle":"2022-01-22T23:24:35.401228Z","shell.execute_reply.started":"2022-01-22T23:24:35.218439Z","shell.execute_reply":"2022-01-22T23:24:35.400176Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"######################数字型数据列偏度校正-【开始】#######################\n#使用skew()方法，计算所有整型和浮点型数据列中，数据分布的偏度（skewness）。\n#偏度是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。亦称偏态、偏态系数。 \nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumerics2 = []\nfor i in data.columns:\n    if data[i].dtype in numeric_dtypes:\n        numerics2.append(i)\nskew_features = data[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n\n#以0.5作为基准，统计偏度超过此数值的高偏度分布数据列，获取这些数据列的index。\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\n#对高偏度数据进行处理，将其转化为正态分布。\n#Box和Cox提出的变换可以使线性回归模型满足线性性、独立性、方差齐次以及正态性的同时，又不丢失信息。\nfor i in skew_index:\n    data[i] = boxcox1p(data[i], boxcox_normmax(data[i] + 1))#这是boxcox1p的使用方法\n######################数字型数据列偏度校正-【结束】#######################","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:37.295148Z","iopub.execute_input":"2022-01-22T23:24:37.295400Z","iopub.status.idle":"2022-01-22T23:24:37.478400Z","shell.execute_reply.started":"2022-01-22T23:24:37.295376Z","shell.execute_reply":"2022-01-22T23:24:37.477899Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.subplot(1,2,1)\nplt.hist(train['LotArea'])\nplt.subplot(1,2,2)\nplt.hist(data['LotArea'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:39.939671Z","iopub.execute_input":"2022-01-22T23:24:39.940960Z","iopub.status.idle":"2022-01-22T23:24:40.300502Z","shell.execute_reply.started":"2022-01-22T23:24:39.940902Z","shell.execute_reply":"2022-01-22T23:24:40.299325Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1440x360 with 2 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"skew_features","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:42.833511Z","iopub.execute_input":"2022-01-22T23:24:42.833746Z","iopub.status.idle":"2022-01-22T23:24:42.844637Z","shell.execute_reply.started":"2022-01-22T23:24:42.833722Z","shell.execute_reply":"2022-01-22T23:24:42.843161Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"MiscVal          21.947195\nPoolArea         16.898328\nLotArea          12.822431\nLowQualFinSF     12.088761\n3SsnPorch        11.376065\nKitchenAbvGr      4.302254\nBsmtFinSF2        4.146143\nEnclosedPorch     4.003891\nScreenPorch       3.946694\nBsmtHalfBath      3.931594\nMasVnrArea        2.613592\nOpenPorchSF       2.535114\nWoodDeckSF        1.842433\n1stFlrSF          1.469604\nBsmtFinSF1        1.425230\nGrLivArea         1.269358\nTotalBsmtSF       1.156894\nBsmtUnfSF         0.919339\n2ndFlrSF          0.861675\nTotRmsAbvGrd      0.758367\nFireplaces        0.733495\nHalfBath          0.694566\nBsmtFullBath      0.624832\nOverallCond       0.570312\nBedroomAbvGr      0.326324\nGarageArea        0.239257\nOverallQual       0.197110\nFullBath          0.167606\nGarageCars       -0.219581\nYearRemodAdd     -0.451020\nYearBuilt        -0.599806\nGarageYrBlt      -3.906205\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"#删除一些特征。df.drop（‘列名’, axis=1）代表将‘列名’对应的列标签（们）沿着水平的方向依次删掉。\ndata = data.drop(['Utilities', 'Street', ], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:45.327633Z","iopub.execute_input":"2022-01-22T23:24:45.327947Z","iopub.status.idle":"2022-01-22T23:24:45.336485Z","shell.execute_reply.started":"2022-01-22T23:24:45.327916Z","shell.execute_reply":"2022-01-22T23:24:45.335375Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#融合多个特征，生成新特征。\ndata['YrBltAndRemod']=data['YearBuilt']+data['YearRemodAdd']\ndata['TotalSF']=data['TotalBsmtSF'] + data['1stFlrSF'] + data['2ndFlrSF']\n\ndata['Total_sqr_footage'] = (data['BsmtFinSF1'] + data['BsmtFinSF2'] +\n                                 data['1stFlrSF'] + data['2ndFlrSF'])\n\ndata['Total_Bathrooms'] = (data['FullBath'] + (0.5 * data['HalfBath']) +\n                               data['BsmtFullBath'] + (0.5 * data['BsmtHalfBath']))\n\ndata['Total_porch_sf'] = (data['OpenPorchSF'] + data['3SsnPorch'] +\n                              data['EnclosedPorch'] + data['ScreenPorch'] +\n                              data['WoodDeckSF'])","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:47.171550Z","iopub.execute_input":"2022-01-22T23:24:47.172640Z","iopub.status.idle":"2022-01-22T23:24:47.184478Z","shell.execute_reply.started":"2022-01-22T23:24:47.172612Z","shell.execute_reply":"2022-01-22T23:24:47.183779Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#简化特征。对于某些分布单调（比如100个数据中有99个的数值是0.9，另1个是0.1）的数字型数据列，进行01取值处理。\ndata['haspool'] = data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndata['has2ndfloor'] = data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasgarage'] = data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasbsmt'] = data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ndata['hasfireplace'] = data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:49.252451Z","iopub.execute_input":"2022-01-22T23:24:49.253997Z","iopub.status.idle":"2022-01-22T23:24:49.270864Z","shell.execute_reply.started":"2022-01-22T23:24:49.253945Z","shell.execute_reply":"2022-01-22T23:24:49.269941Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#检查特征处理后，特征矩阵的维数，核查特征处理结果。\nprint(\"处理之后的特征矩阵维度为:\",data.shape)\n######################特征删除和融合创建新特征-【结束】###################","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:51.294041Z","iopub.execute_input":"2022-01-22T23:24:51.294350Z","iopub.status.idle":"2022-01-22T23:24:51.300532Z","shell.execute_reply.started":"2022-01-22T23:24:51.294325Z","shell.execute_reply":"2022-01-22T23:24:51.299705Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"处理之后的特征矩阵维度为: (2919, 81)\n","output_type":"stream"}]},{"cell_type":"code","source":"def mod_outlier(df):\n        df1 = df.copy()\n        df2 = df1._get_numeric_data()\n        q1 = df.quantile(0.25)\n        q3 = df.quantile(0.75)\n        iqr = q3 - q1\n        lower_bound = q1 -(1.5 * iqr) \n        upper_bound = q3 +(1.5 * iqr)\n        k = 0 \n        for col in df2.columns:\n            print('去除outlier中，进度',k,'/',str(len(df.columns)))\n            k = k+1\n            for i in range(0,len(df[col])):\n                if df2[col][i] < lower_bound[col]:            \n                    df2[col][i] = lower_bound[col]\n                if df2[col][i] > upper_bound[col]:            \n                    df2[col][i] = upper_bound[col]    \n        for col in df2.columns:\n            df1[col] = df2[col]\n        return(df1)\ndata = mod_outlier(data)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:24:53.882716Z","iopub.execute_input":"2022-01-22T23:24:53.883562Z","iopub.status.idle":"2022-01-22T23:24:57.930331Z","shell.execute_reply.started":"2022-01-22T23:24:53.883529Z","shell.execute_reply":"2022-01-22T23:24:57.929395Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"去除outlier中，进度 0 / 81\n去除outlier中，进度 1 / 81\n去除outlier中，进度 2 / 81\n去除outlier中，进度 3 / 81\n去除outlier中，进度 4 / 81\n去除outlier中，进度 5 / 81\n去除outlier中，进度 6 / 81\n去除outlier中，进度 7 / 81\n去除outlier中，进度 8 / 81\n去除outlier中，进度 9 / 81\n去除outlier中，进度 10 / 81\n去除outlier中，进度 11 / 81\n去除outlier中，进度 12 / 81\n去除outlier中，进度 13 / 81\n去除outlier中，进度 14 / 81\n去除outlier中，进度 15 / 81\n去除outlier中，进度 16 / 81\n去除outlier中，进度 17 / 81\n去除outlier中，进度 18 / 81\n去除outlier中，进度 19 / 81\n去除outlier中，进度 20 / 81\n去除outlier中，进度 21 / 81\n去除outlier中，进度 22 / 81\n去除outlier中，进度 23 / 81\n去除outlier中，进度 24 / 81\n去除outlier中，进度 25 / 81\n去除outlier中，进度 26 / 81\n去除outlier中，进度 27 / 81\n去除outlier中，进度 28 / 81\n去除outlier中，进度 29 / 81\n去除outlier中，进度 30 / 81\n去除outlier中，进度 31 / 81\n去除outlier中，进度 32 / 81\n去除outlier中，进度 33 / 81\n去除outlier中，进度 34 / 81\n去除outlier中，进度 35 / 81\n去除outlier中，进度 36 / 81\n去除outlier中，进度 37 / 81\n去除outlier中，进度 38 / 81\n去除outlier中，进度 39 / 81\n去除outlier中，进度 40 / 81\n去除outlier中，进度 41 / 81\n","output_type":"stream"}]},{"cell_type":"code","source":"## 数据归一化\n\nX=pd.get_dummies(data)  ## one hot编码\n\n# Fetch all numeric features\nnumeric_features = X.dtypes[X.dtypes != object].index\nskewed_features = X[numeric_features].apply(lambda x: skew(x)).sort_values(ascending=False)\nhigh_skew = skewed_features[skewed_features > 0.5]\nskew_index = high_skew.index\n\n# Normalize skewed features using log_transformation\n    \nfor i in skew_index:\n    X[i] = np.log1p(X[i])","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:25:00.444694Z","iopub.execute_input":"2022-01-22T23:25:00.445003Z","iopub.status.idle":"2022-01-22T23:25:00.658342Z","shell.execute_reply.started":"2022-01-22T23:25:00.444972Z","shell.execute_reply":"2022-01-22T23:25:00.657121Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# 提取训练数据\nTrain_data=X.loc[\"train\"]\n\n# 提取测试集\nTest_data=X.loc[\"test\"]\n\n# 划分输入输出\nx = Train_data\ny = SalePrice","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:25:03.075338Z","iopub.execute_input":"2022-01-22T23:25:03.075587Z","iopub.status.idle":"2022-01-22T23:25:03.086285Z","shell.execute_reply.started":"2022-01-22T23:25:03.075562Z","shell.execute_reply":"2022-01-22T23:25:03.085255Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"## 划分交叉验证集\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.1,random_state=10)  ## 你可以调整测试集比例","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:25:05.861715Z","iopub.execute_input":"2022-01-22T23:25:05.862011Z","iopub.status.idle":"2022-01-22T23:25:05.874436Z","shell.execute_reply.started":"2022-01-22T23:25:05.861982Z","shell.execute_reply":"2022-01-22T23:25:05.873515Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"##GBR\n\n## 对score 进行反向操作\ndef new_score(x,y):\n    return - mean_squared_error(x,y)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:25:08.735743Z","iopub.execute_input":"2022-01-22T23:25:08.736126Z","iopub.status.idle":"2022-01-22T23:25:08.741432Z","shell.execute_reply.started":"2022-01-22T23:25:08.736092Z","shell.execute_reply":"2022-01-22T23:25:08.740410Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"## 设置初始GradientBoostingRegressor参数\ngbr = GradientBoostingRegressor(n_estimators = 3000,   # 弱学习器的最大迭代次数，或者说最大的弱学习器的个数\n                                learning_rate = 0.02,  # 步长\n                                max_depth = 4,         # 决策树最大深度\n                                max_features = 'sqrt',  # 划分时考虑的最大特征数，划分时最多考虑N^(0.5)个特征\n                                min_samples_leaf = 5,  # 叶子节点最少样本数\n                                min_samples_split = 8,  # 内部节点再划分所需最小样本数\n                                loss = 'huber',         # GBDT算法中的损失函数\n                                random_state = 12,     # 控制随机种子\n                               )      \ngbr.fit(x_train,y_train)  ## 模型训练\nrmse = math.sqrt(mean_squared_error(y_test, gbr.predict(x_test))) ## 模型评估\nprint(\"【gbr】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:25:11.084746Z","iopub.execute_input":"2022-01-22T23:25:11.085008Z","iopub.status.idle":"2022-01-22T23:25:20.143685Z","shell.execute_reply.started":"2022-01-22T23:25:11.084985Z","shell.execute_reply":"2022-01-22T23:25:20.142679Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"【gbr】 mean squares error : 0.09790482653914458\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nstart = time.clock() # 记录开始时间\ncv_sets = ShuffleSplit(random_state = 10,test_size = 0.1, n_splits=5) # shuffling our data for cross-validation\nparameters_gbr = {\n                  'n_estimators':[1000,2000], \n                  'max_depth':[3,4],\n                  }\nscorer_gbr = make_scorer(new_score)\nn_iter_search = 4\ngrid_obj_gbr = RandomizedSearchCV(gbr, \n                                  parameters_gbr,\n                                  scoring = scorer_gbr, \n                                  cv = cv_sets,\n                                  verbose = 5,\n                                  n_jobs = -1,## 使用的processor的个数\n                                  random_state= 99,n_iter=n_iter_search)\ngrid_fit_gbr = grid_obj_gbr.fit(x_train, y_train)\nprint('最佳参数为',grid_fit_gbr.best_estimator_)\nend = time.clock() # 记录结束时间\nxgb_time = (end-start)/60  # 计算训练时间\nprint('RandomizedSearchCV使用了{0:.2f} 分钟进行参数搜索'.format(xgb_time))\n\n## 给出该模型在测试集上的预测分数\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_gbr.predict(x_test)))\nprint(\"【gbr】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:25:22.900077Z","iopub.execute_input":"2022-01-22T23:25:22.900326Z","iopub.status.idle":"2022-01-22T23:26:03.174128Z","shell.execute_reply.started":"2022-01-22T23:25:22.900301Z","shell.execute_reply":"2022-01-22T23:26:03.172695Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 4 candidates, totalling 20 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   15.8s\n[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:   28.4s remaining:    3.2s\n[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   34.2s finished\n","output_type":"stream"},{"name":"stdout","text":"最佳参数为 GradientBoostingRegressor(learning_rate=0.02, loss='huber', max_depth=4,\n                          max_features='sqrt', min_samples_leaf=5,\n                          min_samples_split=8, n_estimators=2000,\n                          random_state=12)\nRandomizedSearchCV使用了0.11 分钟进行参数搜索\n【gbr】 mean squares error : 0.0969548354091291\n","output_type":"stream"}]},{"cell_type":"code","source":"##LGBM\n\n## 设置初始LGBMRegressor参数\nlightgbm = LGBMRegressor(objective='regression', \n                           num_leaves=4,\n                           learning_rate=0.01, \n                           n_estimators=1000,\n                           max_bin=100, \n                           bagging_fraction=0.7,\n                           bagging_freq=5, \n                           bagging_seed=7,\n                           feature_fraction=0.2,\n                           feature_fraction_seed=7,\n                           verbose=-1,\n                           )\nlightgbm.fit(x_train,y_train)        ## 模型训练\nrmse = math.sqrt(mean_squared_error(y_test, lightgbm.predict(x_test))) ## 模型评估\nprint(\"【lightgbm】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:26:29.947205Z","iopub.execute_input":"2022-01-22T23:26:29.947508Z","iopub.status.idle":"2022-01-22T23:26:30.534727Z","shell.execute_reply.started":"2022-01-22T23:26:29.947477Z","shell.execute_reply":"2022-01-22T23:26:30.534257Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n【lightgbm】 mean squares error : 0.10596720059300946\n","output_type":"stream"}]},{"cell_type":"code","source":"## start = time() # 记录开始时间\nparameters_lgbm = {\n                  'n_estimators':[3000,4000,5000], \n                  'max_bin':[100,200], \n                  }\nscorer_lgbm = make_scorer(new_score)\ngrid_obj_lgbm = RandomizedSearchCV(lightgbm, \n                                   parameters_lgbm,\n                                   scoring = scorer_lgbm, \n                                   cv = cv_sets,\n                                   verbose=5,\n                                   n_jobs = -1,\n                                   random_state= 99\n                                  )\ngrid_fit_lgbm = grid_obj_lgbm.fit(x_train, y_train)\nprint('最佳参数为',grid_fit_lgbm.best_estimator_)\n# end = time() # 记录结束时间\nlgbm_time = (end-start)/60  # 计算训练时间\nprint('LGBM使用了{0:.2f} 分钟进行参数搜索'.format(lgbm_time))\n## 给出该模型在测试集上的预测分数\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_lgbm.predict(x_test)))\nprint(\"【LGBM】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:26:33.345386Z","iopub.execute_input":"2022-01-22T23:26:33.346127Z","iopub.status.idle":"2022-01-22T23:26:58.276917Z","shell.execute_reply.started":"2022-01-22T23:26:33.346097Z","shell.execute_reply":"2022-01-22T23:26:58.276235Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 6 candidates, totalling 30 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    7.7s\n[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   22.3s remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   22.3s finished\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n最佳参数为 LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, bagging_seed=7,\n              feature_fraction=0.2, feature_fraction_seed=7, learning_rate=0.01,\n              max_bin=100, n_estimators=5000, num_leaves=4,\n              objective='regression', verbose=-1)\nLGBM使用了0.11 分钟进行参数搜索\n【LGBM】 mean squares error : 0.10438703041436787\n","output_type":"stream"}]},{"cell_type":"code","source":"xgboost = XGBRegressor(learning_rate=0.01,\n                       n_estimators=2000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:squarederror',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=12)\nxgboost.fit(x_train,y_train)  ## 模型训练\ny_predictrfr = xgboost.predict(x_test)  ## 模型自预测\n\nrmse = math.sqrt(mean_squared_error(y_test, xgboost.predict(x_test)))\nprint(\"【xgboost】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:27:02.866510Z","iopub.execute_input":"2022-01-22T23:27:02.866727Z","iopub.status.idle":"2022-01-22T23:27:17.297587Z","shell.execute_reply.started":"2022-01-22T23:27:02.866704Z","shell.execute_reply":"2022-01-22T23:27:17.296901Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"【xgboost】 mean squares error : 0.09743198532587236\n","output_type":"stream"}]},{"cell_type":"code","source":"## start = time() # Get start time\nparameters_xgb = {'n_estimators':[2000,4000], \n             'max_depth':[3,4],\n            }\nscorer_xgb = make_scorer(new_score)\ngrid_obj_xgb = RandomizedSearchCV(xgboost, \n                                 parameters_xgb,\n                                 scoring = scorer_xgb, \n                                 verbose = 10,\n                                 n_jobs = -1,\n                                 cv = cv_sets,\n                                 random_state= 99)\ngrid_fit_xgboost = grid_obj_xgb.fit(x_train, y_train)\n\nprint('最佳参数为',grid_fit_xgboost.best_estimator_)\n# end = time() # 记录结束时间\n# lgbm_time = (end-start)/60  # 计算训练时间\nprint('xgboost使用了{0:.2f} 分钟进行参数搜索'.format(lgbm_time))\n## 给出该模型在测试集上的预测分数\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_xgboost.predict(x_test)))\nprint(\"【xgboost】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T23:27:21.313159Z","iopub.execute_input":"2022-01-22T23:27:21.313403Z","iopub.status.idle":"2022-01-23T01:20:55.981235Z","shell.execute_reply.started":"2022-01-22T23:27:21.313378Z","shell.execute_reply":"2022-01-23T01:20:55.980228Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 4 candidates, totalling 20 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed: 26.0min\n[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 57.8min\n[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed: 104.0min remaining: 26.0min\n[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 113.3min finished\n","output_type":"stream"},{"name":"stdout","text":"最佳参数为 XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.7, enable_categorical=False,\n             gamma=0, gpu_id=-1, importance_type=None,\n             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n             max_depth=4, min_child_weight=0, missing=nan,\n             monotone_constraints='()', n_estimators=2000, n_jobs=4, nthread=-1,\n             num_parallel_tree=1, predictor='auto', random_state=12,\n             reg_alpha=6e-05, reg_lambda=1, scale_pos_weight=1, seed=27,\n             subsample=0.7, tree_method='exact', validate_parameters=1,\n             verbosity=None)\nxgboost使用了0.11 分钟进行参数搜索\n【xgboost】 mean squares error : 0.09743198532587236\n[CV] n_estimators=1000, max_depth=3 ..................................\n[CV] ..... n_estimators=1000, max_depth=3, score=-0.010, total=   3.2s\n[CV] n_estimators=1000, max_depth=3 ..................................\n[CV] ..... n_estimators=1000, max_depth=3, score=-0.029, total=   3.1s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.015, total=   6.1s\n[CV] n_estimators=1000, max_depth=4 ..................................\n[CV] ..... n_estimators=1000, max_depth=4, score=-0.014, total=   4.5s\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.013, total=   8.2s\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.026, total=   6.9s\n[CV] n_estimators=3000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=100, score=-0.014, total=   2.0s\n[CV] n_estimators=4000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=100, score=-0.012, total=   2.1s\n[CV] n_estimators=4000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=100, score=-0.026, total=   2.6s\n[CV] n_estimators=5000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=100, score=-0.014, total=   3.4s\n[CV] n_estimators=3000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=200, score=-0.014, total=   2.0s\n[CV] n_estimators=4000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=200, score=-0.012, total=   2.6s\n[CV] n_estimators=4000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=200, score=-0.026, total=   2.6s\n[CV] n_estimators=5000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=200, score=-0.014, total=   3.0s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.018, total=12.9min\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.019, total=13.1min\n[CV] n_estimators=4000, max_depth=3 ..................................\n[CV] ..... n_estimators=4000, max_depth=3, score=-0.016, total=27.3min\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.017, total=18.4min\n[CV] n_estimators=4000, max_depth=4 ..................................\n[CV] ..... n_estimators=4000, max_depth=4, score=-0.014, total=37.9min\n[CV] n_estimators=1000, max_depth=3 ..................................\n[CV] ..... n_estimators=1000, max_depth=3, score=-0.014, total=   3.6s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.014, total=   7.0s\n[CV] n_estimators=1000, max_depth=4 ..................................\n[CV] ..... n_estimators=1000, max_depth=4, score=-0.013, total=   5.2s\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.010, total=   9.6s\n[CV] n_estimators=3000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=100, score=-0.012, total=   2.4s\n[CV] n_estimators=4000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=100, score=-0.013, total=   3.1s\n[CV] n_estimators=5000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=100, score=-0.012, total=   3.9s\n[CV] n_estimators=3000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=200, score=-0.013, total=   2.0s\n[CV] n_estimators=3000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=200, score=-0.027, total=   2.0s\n[CV] n_estimators=4000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=200, score=-0.014, total=   2.6s\n[CV] n_estimators=5000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=200, score=-0.013, total=   3.3s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.013, total=13.2min\n[CV] n_estimators=4000, max_depth=3 ..................................\n[CV] ..... n_estimators=4000, max_depth=3, score=-0.013, total=26.6min\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.012, total=18.0min\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.017, total=18.1min\n[CV] n_estimators=4000, max_depth=4 ..................................\n[CV] ..... n_estimators=4000, max_depth=4, score=-0.017, total=36.7min\n[CV] n_estimators=1000, max_depth=3 ..................................\n[CV] ..... n_estimators=1000, max_depth=3, score=-0.015, total=   3.1s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.013, total=   6.0s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.029, total=   6.3s\n[CV] n_estimators=1000, max_depth=4 ..................................\n[CV] ..... n_estimators=1000, max_depth=4, score=-0.028, total=   4.3s\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.015, total=   7.7s\n[CV] n_estimators=3000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=100, score=-0.013, total=   2.0s\n[CV] n_estimators=4000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=100, score=-0.012, total=   2.6s\n[CV] n_estimators=5000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=100, score=-0.012, total=   3.2s\n[CV] n_estimators=5000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=100, score=-0.025, total=   4.0s\n[CV] n_estimators=4000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=200, score=-0.012, total=   3.1s\n[CV] n_estimators=5000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=200, score=-0.012, total=   3.9s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.012, total=13.3min\n[CV] n_estimators=4000, max_depth=3 ..................................\n[CV] ..... n_estimators=4000, max_depth=3, score=-0.018, total=26.5min\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.013, total=17.9min\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.016, total=18.3min\n[CV] n_estimators=4000, max_depth=4 ..................................\n[CV] ..... n_estimators=4000, max_depth=4, score=-0.016, total=36.9min\n[CV] n_estimators=1000, max_depth=3 ..................................\n[CV] ..... n_estimators=1000, max_depth=3, score=-0.013, total=   3.2s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.010, total=   6.2s\n[CV] n_estimators=1000, max_depth=4 ..................................\n[CV] ..... n_estimators=1000, max_depth=4, score=-0.010, total=   4.3s\n[CV] n_estimators=1000, max_depth=4 ..................................\n[CV] ..... n_estimators=1000, max_depth=4, score=-0.015, total=   4.4s\n[CV] n_estimators=2000, max_depth=4 ..................................\n[CV] ..... n_estimators=2000, max_depth=4, score=-0.014, total=   8.2s\n[CV] n_estimators=3000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=100, score=-0.012, total=   1.6s\n[CV] n_estimators=3000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=100, score=-0.027, total=   1.9s\n[CV] n_estimators=4000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=100, score=-0.014, total=   2.6s\n[CV] n_estimators=5000, max_bin=100 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=100, score=-0.013, total=   2.5s\n[CV] n_estimators=3000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=200, score=-0.012, total=   2.2s\n[CV] n_estimators=3000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=3000, max_bin=200, score=-0.014, total=   2.0s\n[CV] n_estimators=4000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=4000, max_bin=200, score=-0.014, total=   2.6s\n[CV] n_estimators=5000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=200, score=-0.012, total=   3.3s\n[CV] n_estimators=5000, max_bin=200 ..................................\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n[CV] ..... n_estimators=5000, max_bin=200, score=-0.025, total=   2.5s\n[CV] n_estimators=2000, max_depth=3 ..................................\n[CV] ..... n_estimators=2000, max_depth=3, score=-0.016, total=13.2min\n[CV] n_estimators=4000, max_depth=3 ..................................\n[CV] ..... n_estimators=4000, max_depth=3, score=-0.012, total=26.6min\n[CV] n_estimators=4000, max_depth=3 ..................................\n[CV] ..... n_estimators=4000, max_depth=3, score=-0.018, total=26.7min\n[CV] n_estimators=4000, max_depth=4 ..................................\n[CV] ..... n_estimators=4000, max_depth=4, score=-0.012, total=37.6min\n[CV] n_estimators=4000, max_depth=4 ..................................\n[CV] ..... n_estimators=4000, max_depth=4, score=-0.017, total= 9.3min\n","output_type":"stream"}]},{"cell_type":"code","source":"##LASSO\n\nfrom sklearn import linear_model\nLasso = linear_model.Lasso(alpha=0.0005,\n                         max_iter=1000,\n                         selection='random',\n                        )\nLasso.fit(x_train,y_train)\nrmse = math.sqrt(mean_squared_error(y_test, Lasso.predict(x_test)))\nprint(\"【Lasso】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:27:35.637233Z","iopub.execute_input":"2022-01-23T01:27:35.637791Z","iopub.status.idle":"2022-01-23T01:27:35.868145Z","shell.execute_reply.started":"2022-01-23T01:27:35.637611Z","shell.execute_reply":"2022-01-23T01:27:35.867419Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"【Lasso】 mean squares error : 0.09339713716048807\n","output_type":"stream"}]},{"cell_type":"code","source":"## start = time() # Get start time\nparameters_lasso = {'alpha':[0.0005,0.001,0.002], \n             'max_iter':[1000,2000,3000], \n            'selection':['random','cyclic']\n             }\nscorer_lasso = make_scorer(new_score)\ngrid_obj_lasso = RandomizedSearchCV(Lasso, \n                                 parameters_lasso,\n                                 scoring = scorer_lasso, \n                                 cv = cv_sets,\n                                 random_state= 99)\ngrid_fit_lasso = grid_obj_lasso.fit(x_train, y_train)\n\nprint('最佳参数为',grid_fit_lasso.best_estimator_)\n#end = time() # 记录结束时间\n# lgbm_time = (end-start)/60  # 计算训练时间\nprint('lasso使用了{0:.2f} 分钟进行参数搜索'.format(lgbm_time))\n## 给出该模型在测试集上的预测分数\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_lasso.predict(x_test)))\nprint(\"【lasso】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:27:38.855510Z","iopub.execute_input":"2022-01-23T01:27:38.855824Z","iopub.status.idle":"2022-01-23T01:27:54.659091Z","shell.execute_reply.started":"2022-01-23T01:27:38.855793Z","shell.execute_reply":"2022-01-23T01:27:54.658401Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"最佳参数为 Lasso(alpha=0.0005, selection='random')\nlasso使用了0.11 分钟进行参数搜索\n【lasso】 mean squares error : 0.093401972943006\n","output_type":"stream"}]},{"cell_type":"code","source":"#RFR\n\nfrom sklearn.ensemble import RandomForestRegressor  ## 回归决策树\n\nrfr=RandomForestRegressor(n_estimators = 50,  ## 森林中树的个数\n                          random_state= 10,  ## 固定随机种子\n                          min_impurity_decrease=0.002, # 一般不推荐改动\n                          min_weight_fraction_leaf=0.001, # 叶子节点最小的样本权重，如果小于这个值，则会和兄弟节点一起被剪枝。\n                          min_samples_split=5,#如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分\n                         )\nrfr.fit(x_train,y_train)  ## 模型训练\ny_predictrfr = rfr.predict(x_test)  ## 模型自预测","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:28:37.338661Z","iopub.execute_input":"2022-01-23T01:28:37.338989Z","iopub.status.idle":"2022-01-23T01:28:38.048176Z","shell.execute_reply.started":"2022-01-23T01:28:37.338955Z","shell.execute_reply":"2022-01-23T01:28:38.046389Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"cv_sets = ShuffleSplit(random_state = 10, test_size = 0.1, n_splits = 5)\nparameters_rfr = {\n                 'n_estimators':[1000, 2000]\n                 }\nscorer_rfr = make_scorer(new_score)\ngrid_obj_rfr = RandomizedSearchCV(rfr, \n                                 parameters_rfr,\n                                 scoring = scorer_rfr, \n                                 cv = cv_sets,\n                                 verbose=5,\n                                 n_jobs=-1,\n                                 random_state= 99)\ngrid_fit_rfr = grid_obj_rfr.fit(x_train, y_train)\n\nprint('最佳参数为',grid_obj_rfr.best_estimator_)\n#end = time() # 记录结束时间\n# lgbm_time = (end-start)/60  # 计算训练时间\n# print('lasso使用了{0:.2f} 分钟进行参数搜索'.format(lgbm_time))\n## 给出该模型在测试集上的预测分数\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_rfr.predict(x_test)))\nprint(\"【rfr】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:28:42.806573Z","iopub.execute_input":"2022-01-23T01:28:42.806893Z","iopub.status.idle":"2022-01-23T01:30:01.075976Z","shell.execute_reply.started":"2022-01-23T01:28:42.806856Z","shell.execute_reply":"2022-01-23T01:30:01.075052Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 2 candidates, totalling 10 fits\n","output_type":"stream"},{"name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   45.2s remaining:   30.1s\n[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.1min finished\n","output_type":"stream"},{"name":"stdout","text":"最佳参数为 RandomForestRegressor(min_impurity_decrease=0.002, min_samples_split=5,\n                      min_weight_fraction_leaf=0.001, n_estimators=1000,\n                      random_state=10)\n【rfr】 mean squares error : 0.1804491004543663\n","output_type":"stream"}]},{"cell_type":"code","source":"## 计算均方差\nimport math\nfrom sklearn.metrics import mean_squared_error, make_scorer\n\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_gbr.predict(x_test)))\nprint(\"【gbr】 mean squares error :\",rmse)\n\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_lgbm.predict(x_test)))\nprint(\"【lightgbm】 mean squares error :\",rmse)\n\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_xgboost.predict(x_test)))\nprint(\"【xgboost】 mean squares error :\",rmse)\n\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_lasso.predict(x_test)))\nprint(\"【Lasso】 mean squares error :\",rmse)\n\nrmse = math.sqrt(mean_squared_error(y_test, grid_fit_rfr.predict(x_test)))\nprint(\"【rfr】 mean squares error :\",rmse)\n\n#融合预测结果，提高稳定性\nblend_res = 0.2 * grid_fit_gbr.predict(x_test) + \\\n            0.2 * grid_fit_lgbm.predict(x_test) + \\\n            0.2 * grid_fit_xgboost.predict(x_test) + \\\n            0.2 * grid_fit_lasso.predict(x_test) +\\\n            0.2 * grid_fit_rfr.predict(x_test)\n\nrmse = math.sqrt(mean_squared_error(y_test, blend_res))\nprint(\"【blend_res】 mean squares error :\",rmse)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:34:24.930895Z","iopub.execute_input":"2022-01-23T01:34:24.931226Z","iopub.status.idle":"2022-01-23T01:34:25.258958Z","shell.execute_reply.started":"2022-01-23T01:34:24.931194Z","shell.execute_reply":"2022-01-23T01:34:25.258424Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"【gbr】 mean squares error : 0.0969548354091291\n【lightgbm】 mean squares error : 0.10438703041436787\n【xgboost】 mean squares error : 0.09743198532587236\n【Lasso】 mean squares error : 0.093401972943006\n【rfr】 mean squares error : 0.1804491004543663\n【blend_res】 mean squares error : 0.10040005364800209\n","output_type":"stream"}]},{"cell_type":"code","source":"# 预测\ny_model_prerfc_gbr = grid_fit_gbr.predict(Test_data)\ny_model_prerfc_lightgbm = grid_fit_lgbm.predict(Test_data)\ny_model_prerfc_xgboost = grid_fit_xgboost.predict(Test_data)\ny_model_prerfc_lasso = grid_fit_lasso.predict(Test_data)\ny_model_prerfc_rfr = grid_fit_rfr.predict(Test_data)\n\ny_model_prerfc = np.exp(0.2*y_model_prerfc_gbr+\n                        0.2*y_model_prerfc_lightgbm+\n                        0.2*y_model_prerfc_xgboost+\n                        0.2*y_model_prerfc_lasso+\n                        0.2*y_model_prerfc_rfr\n                       )\n# 查看预测结果\ny_model_prerfc=np.around(y_model_prerfc,0)\nprediction=np.array(y_model_prerfc).tolist()\ny_model_prerfc","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:34:28.425210Z","iopub.execute_input":"2022-01-23T01:34:28.425462Z","iopub.status.idle":"2022-01-23T01:34:28.800479Z","shell.execute_reply.started":"2022-01-23T01:34:28.425437Z","shell.execute_reply":"2022-01-23T01:34:28.799276Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array([122300., 156380., 180927., ..., 160985., 120860., 228243.])"},"metadata":{}},{"name":"stdout","text":"[CV] n_estimators=1000 ...............................................\n[CV] .................. n_estimators=1000, score=-0.033, total=  14.5s\n[CV] n_estimators=2000 ...............................................\n[CV] .................. n_estimators=2000, score=-0.033, total=  31.1s\n[CV] n_estimators=1000 ...............................................\n[CV] .................. n_estimators=1000, score=-0.028, total=  16.1s\n[CV] n_estimators=2000 ...............................................\n[CV] .................. n_estimators=2000, score=-0.028, total=  30.6s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# test = test.drop('SalePrice',axis=1)  ## 第二次运行请取消注释","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:34:35.542507Z","iopub.execute_input":"2022-01-23T01:34:35.543694Z","iopub.status.idle":"2022-01-23T01:34:35.547697Z","shell.execute_reply.started":"2022-01-23T01:34:35.543627Z","shell.execute_reply":"2022-01-23T01:34:35.547163Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"## 保存预测结果\nprediction=np.array(y_model_prerfc).tolist()\ntest.insert(1,column=\"SalePrice\",value=prediction)\n## 提取预测结果\npredict_sub=test.drop(test.iloc[:,2:],axis=1)\n## 查看预测信息\npredict_sub.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:34:37.821185Z","iopub.execute_input":"2022-01-23T01:34:37.821435Z","iopub.status.idle":"2022-01-23T01:34:37.832810Z","shell.execute_reply.started":"2022-01-23T01:34:37.821409Z","shell.execute_reply":"2022-01-23T01:34:37.831743Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(1459, 2)"},"metadata":{}},{"name":"stdout","text":"[CV] n_estimators=1000 ...............................................\n[CV] .................. n_estimators=1000, score=-0.028, total=  14.4s\n[CV] n_estimators=1000 ...............................................\n[CV] .................. n_estimators=1000, score=-0.052, total=  14.4s\n[CV] n_estimators=2000 ...............................................\n[CV] .................. n_estimators=2000, score=-0.033, total=  25.9s\n","output_type":"stream"}]},{"cell_type":"code","source":"# 保存预测结果\npredict_sub.to_csv('predictions_stack_gen_v13.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T01:34:46.244782Z","iopub.execute_input":"2022-01-23T01:34:46.245483Z","iopub.status.idle":"2022-01-23T01:34:46.253209Z","shell.execute_reply.started":"2022-01-23T01:34:46.245455Z","shell.execute_reply":"2022-01-23T01:34:46.252393Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"[CV] n_estimators=1000 ...............................................\n[CV] .................. n_estimators=1000, score=-0.033, total=  14.1s\n[CV] n_estimators=2000 ...............................................\n[CV] .................. n_estimators=2000, score=-0.028, total=  28.7s\n[CV] n_estimators=2000 ...............................................\n[CV] .................. n_estimators=2000, score=-0.051, total=  21.6s\n","output_type":"stream"}]}]}